{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "azGXRwvpSJWl7lvs6Pg1j7",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Activation, Flatten, Reshape, Dropout, UpSampling2D, MaxPooling2D, BatchNormalization, Concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Conv2D, UpSampling2D, BatchNormalization, concatenate, Flatten\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Conv2D, UpSampling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import cv2\n",
    "import os \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "tKdGcu2fE4rF69Ch0YGmmh",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# directory paths \n",
    "train_path = 'wm-nowm/train' # training directory\n",
    "valid_path = 'wm-nowm/train' # validation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "PHbJgQEC7W1WLFHHVl4rno",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def take_file_name(filedir): # remove just file name from directory and return\n",
    "    # filename = np.array(filedir.split('/'))[-1].split('.')[0] # take out the name, isolate the jpeg, then return the name\n",
    "    filename = np.array(filedir.split('/'))[-1] # take out the name, then return the name\n",
    "    # print(filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "ssgZAU5bTJnWqR2GLIGqga",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def match_file_names(watermarkedarr, nonwatermarkedarr, dname_wm, dname_nwm):\n",
    "    sortedwmarr = np.array([])\n",
    "    sortednwmarr = np.array([])\n",
    "    \n",
    "    wmarr = list(watermarkedarr)\n",
    "    nwmarr = list(nonwatermarkedarr)\n",
    "    \n",
    "    length = len(watermarkedarr) if len(watermarkedarr) >= len(nonwatermarkedarr) else len(nonwatermarkedarr)\n",
    "    \n",
    "    for pos in range(length):\n",
    "        try:\n",
    "            if length == len(watermarkedarr): # more images in watermarked array\n",
    "                exist_nwm = nwmarr.index(wmarr[pos])\n",
    "                sortedwmarr = np.append(sortedwmarr, dname_wm + watermarkedarr[pos]) # this is the iterable\n",
    "                sortednwmarr = np.append(sortednwmarr, dname_nwm + nonwatermarkedarr[exist_nwm]) # this is the match\n",
    "            elif length == len(nonwatermarkedarr): # more images in nonwatermarked array\n",
    "                exist_wm = wmarr.index(nwmarr[pos])\n",
    "                sortedwmarr = np.append(sortedwmarr, dname_wm + watermarkedarr[exist_wm]) # this is the match\n",
    "                sortednwmarr = np.append(sortednwmarr, dname_nwm + nonwatermarkedarr[pos]) # this is the iterable\n",
    "        except ValueError: \n",
    "            continue\n",
    "    return sortedwmarr, sortednwmarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "YmUbWD2LYRLzzwET2Qk13l",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Sort the watermarked and non watermarked images into parallel arrays so NN will use it better\n",
    "\n",
    "train_path_watermarked_images = \"wm-nowm/train/watermark/\"\n",
    "train_path_nonwatermarked_images = \"wm-nowm/train/no-watermark/\"\n",
    "\n",
    "tp_watermarked = np.array([])  # array with watermarked image names\n",
    "tp_nonwatermarked = np.array([])  # array with nonwatermarked image names\n",
    "\n",
    "for root, dirs, files in os.walk(\n",
    "    train_path_watermarked_images, topdown=True\n",
    "):  # data length = 12510\n",
    "    for file in files:\n",
    "        tp_watermarked = np.append(\n",
    "            tp_watermarked, take_file_name(file)\n",
    "        )  # append just the name of the file into array\n",
    "\n",
    "for root, dirs, files in os.walk(\n",
    "    train_path_nonwatermarked_images, topdown=True\n",
    "):  # data length = 12477\n",
    "    for file in files:\n",
    "        tp_nonwatermarked = np.append(\n",
    "            tp_nonwatermarked, take_file_name(file)\n",
    "        )  # append just the name of the file into array\n",
    "\n",
    "tp_watermarked_sorted, tp_nonwatermarked_sorted = match_file_names(\n",
    "    tp_watermarked,\n",
    "    tp_nonwatermarked,\n",
    "    train_path_watermarked_images,\n",
    "    train_path_nonwatermarked_images,\n",
    ")\n",
    "\n",
    "\n",
    "valid_path_watermarked_images = \"wm-nowm/valid/watermark/\"\n",
    "valid_path_nonwatermarked_images = \"wm-nowm/valid/no-watermark/\"\n",
    "\n",
    "vp_watermarked = np.array([])  # array with watermarked image names\n",
    "vp_nonwatermarked = np.array([])  # array with nonwatermarked image names\n",
    "\n",
    "for root, dirs, files in os.walk(\n",
    "    valid_path_watermarked_images, topdown=True\n",
    "):  # data length = 3299\n",
    "    for file in files:\n",
    "        vp_watermarked = np.append(\n",
    "            vp_watermarked, take_file_name(file)\n",
    "        )  # append just the name of the file into array\n",
    "\n",
    "for root, dirs, files in os.walk(\n",
    "    valid_path_nonwatermarked_images, topdown=True\n",
    "):  # data length = 3289\n",
    "    for file in files:\n",
    "        vp_nonwatermarked = np.append(\n",
    "            vp_nonwatermarked, take_file_name(file)\n",
    "        )  # append just the name of the file into array\n",
    "\n",
    "vp_watermarked_sorted, vp_nonwatermarked_sorted = match_file_names(\n",
    "    vp_watermarked,\n",
    "    vp_nonwatermarked,\n",
    "    valid_path_watermarked_images,\n",
    "    valid_path_nonwatermarked_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "S0fvpbZDdFzxOj1rlvD5tj",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# dimension to resize to \n",
    "width = 128 # only certain dimensions work due to UpSampling (196x196 works, 148x148 works)\n",
    "height = 128\n",
    "dim = (width, height) # set the dimensions\n",
    "\n",
    "def create_pixel_arr(files):\n",
    "    data = []\n",
    "    for image in files:\n",
    "        try: # take each image and use imread to get the pixel values in a matrix \n",
    "            img_arr = cv2.imread(image, cv2.IMREAD_COLOR)\n",
    "            resized_arr = cv2.resize(img_arr, (width, height)) # rescale the image so every image is of the same dimension\n",
    "            data.append(resized_arr) # add the matrix of pixel values \n",
    "        except Exception as e:\n",
    "            print(e) # some error thrown in imread or resize\n",
    "    return np.array(data)\n",
    "\n",
    "train_wms_pixVals = create_pixel_arr(tp_watermarked_sorted)\n",
    "train_nwms_pixVals = create_pixel_arr(tp_nonwatermarked_sorted)\n",
    "\n",
    "val_wms_pixVals = create_pixel_arr(vp_watermarked_sorted)\n",
    "val_nwms_pixVals = create_pixel_arr(vp_nonwatermarked_sorted) # make ndarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "0UOgzCZw9vsDCNVwIh8hF9",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# TODO use sklearn to split tp_wms_pixVals, tp_nwms_pixVals into training and testing sets\n",
    "# use variables names: X_train, y_train, X_test, y_test\n",
    "# 80% training, 20% testing, amount of shuffling applied\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_wms_pixVals, train_nwms_pixVals, train_size=0.8, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "eg4ddg1BWFZK7EWO2jIbBY",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "train_wms_pixVals = 0 \n",
    "train_nwms_pixVals = 0 \n",
    "val_wms_pixVals = 0 \n",
    "val_nwms_pixVals = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "MxWrifdb4vxQDlsB98MCyK",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,25))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(cv2.cvtColor(X_test[i], cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "L7i8fYBbiFGcqXPJoAHdxG",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to data augment images \n",
    "\n",
    "def data_augmentation(inputImage): # run image through all augmentation methods\n",
    "    return random_contrast(random_brightness(inputImage)).numpy()\n",
    "    # return randomCrop(randomFlip(inputImage)) # use augmentation methods without messing with colour \n",
    "\n",
    "def random_flip(pic): # flips the image up and down before left and right at random\n",
    "    return tf.image.random_flip_up_down(tf.image.random_flip_left_right(pic, 1), 1)\n",
    "\n",
    "# def randomCrop(pic): # crops the image from a randomly defined width and height, that are under the intial image width and height\n",
    "#     return tf.image.random_crop(pic, size=[random.randint(75,width), random.randint(75,height), 3], seed=None)\n",
    "\n",
    "def random_brightness(pic): # makes the image a random brightness from 1% to 20%\n",
    "    return tf.image.random_brightness(pic, random.uniform(0.01, 0.2), 1)\n",
    "\n",
    "def random_contrast(pic): # contrasts the image from 5% to 50%\n",
    "    return tf.image.random_contrast(pic, 0.2, 0.7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "Xb87zRSZRjmKYUXjUxeyWK",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Output Tensorflow data augmented images\n",
    "plt.figure(figsize=(25,25))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    augmented_image = data_augmentation(X_train[random.randint(1, len(X_train))]) # send 25 images into data augmentation\n",
    "    plt.imshow(cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB)) # not using cv2 as it messed up the code\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "gIZq60Ln7A59Rx0gths3Dl",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# apply data augmentation to the X_train and y_train\n",
    "\n",
    "data_augmented_X = [] \n",
    "data_augmented_y = []\n",
    "\n",
    "for image in X_train:\n",
    "    data_augmented_X.append(data_augmentation(image))\n",
    "    \n",
    "for image in y_train:\n",
    "    data_augmented_y.append(data_augmentation(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "TT31cd9gAiheMIn35ZZAVq",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,25))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(cv2.cvtColor(data_augmented_X[i], cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "C8fXzou6aDZjDqfpFwURvN",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,25))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(cv2.cvtColor(data_augmented_y[i], cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "96jDn9WvO5YLR3Ir3B44lK",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.append(X_train, data_augmented_X, axis=0)\n",
    "y_train = np.append(y_train, data_augmented_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "ZzQ0aQZeek3sUnMlkbDTk6",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# normalize \n",
    "X_train = X_train / 255\n",
    "y_train = y_train / 255\n",
    "X_test = X_test / 255\n",
    "y_test = y_test / 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "fKaqV7jv3GaM2Kd2ECHGSI",
     "type": "MD"
    }
   },
   "source": [
    "================================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "lqkftVR9HnOQyZI3N5zTS7",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def generate_generator():\n",
    "    x = Input(shape=(width, height, 3)) #196\n",
    "\n",
    "    # downsample\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2))(conv1) #98\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "    \n",
    "    # middle\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    \n",
    "    # upsample\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv5))\n",
    "    up6 = BatchNormalization()(up6)\n",
    "    merge6 = keras.layers.concatenate([conv4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "     \n",
    "\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv6))\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    merge7 = keras.layers.concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv7))\n",
    "    up8 = BatchNormalization()(up8)\n",
    "    merge8 = keras.layers.concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv8))\n",
    "    up9 = BatchNormalization()(up9)\n",
    "    merge9 = keras.layers.concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    # output\n",
    "    output = Conv2D(3, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    return Model(inputs=x, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "YOeg7gkup0kSGDd6sVkfMW",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def generate_discriminador():\n",
    "    inputs = Input(shape=(width, height, 3))\n",
    "\n",
    "    # downsample\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    #conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    #conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2))(conv1) #98\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    #conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    #conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    #conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    #conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    #conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    #conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    #conv4 = BatchNormalization()(conv4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "\n",
    "    flatten = Flatten()(conv5)\n",
    "    reshape = Dense(128, activation='relu')(flatten)\n",
    "    output = Dense(1, activation='sigmoid')(reshape)\n",
    "    \n",
    "\n",
    "    return Model(inputs=inputs, outputs=[output, inputs])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "jpb2uKKryB1aHeLcSiXUkc",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "generator = generate_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "42AqCVrfatRZ8s15FBO10X",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "discriminator = generate_discriminador()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "uqkUcQDT8AaKtBJE5tbZ6L",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "img_with_watermark = Input(shape=(width, height, 3))\n",
    "\n",
    "generator_out = generator(img_with_watermark)\n",
    "\n",
    "discriminator_out = discriminator(generator_out)\n",
    "\n",
    "combined = Model(img_with_watermark, discriminator_out)\n",
    "\n",
    "combined.compile(loss=['binary_crossentropy', 'mse'], optimizer=Adam(learning_rate=0.0001),loss_weights=[1, 9]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "jiEczVPYYe5HfVnWUA9HQx",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train, generator, discriminator, combined, epochs, batch_size=32, sample_interval=100):\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    history = {\n",
    "        'd_loss' : [],\n",
    "        'd_acc' : [],\n",
    "        'g_loss' : []\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"----EPOCH \" + str(epoch) + '-----')\n",
    "        for batch in range(int(len(X_train)/batch_size)):\n",
    "\n",
    "            #  Train the Discriminator\n",
    "            imgs_with_watermark = X_train[batch*batch_size : (batch+1)*batch_size]\n",
    "\n",
    "            # El generador ahora deberá admitir el noise la mismo tiempo que los gen_labels generados aleatoriamente\n",
    "            gen_imgs = generator.predict(imgs_with_watermark, verbose=0)\n",
    "\n",
    "            imgs_without_watermark = y_train[batch*batch_size : (batch+1)*batch_size]\n",
    "\n",
    "            # Añadir a las salidas deseadas del discriminador las etiquetas aleatorias y las obtenidas de y_train\n",
    "            d_loss_real = discriminator.train_on_batch(imgs_without_watermark, [valid, imgs_without_watermark])\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_imgs, [fake, gen_imgs])\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Train the Generator\n",
    "            # Añadir como entrada y salida las etiquetas generadas\n",
    "            g_loss = combined.train_on_batch(imgs_with_watermark, [valid, imgs_without_watermark])\n",
    "\n",
    "            # Save losses\n",
    "            history['d_loss'].append(d_loss[0])\n",
    "            history['d_acc'].append(d_loss[3])\n",
    "            history['g_loss'].append(g_loss)\n",
    "\n",
    "            # Plot the progress\n",
    "            if batch % 50 == 0:\n",
    "                print (\"%d [D loss: %.4f,\\t acc.: %.2f%%]\\t[G loss: %.4f]\" % (batch, d_loss[0], 100*d_loss[3], g_loss[0]))\n",
    "\n",
    "            if batch % 500 == 0:\n",
    "                sample_images(epoch, batch, gen_imgs, imgs_without_watermark) # TODO CAMBIAR ESTO POR LAS VARIABLES NUESTRAS\n",
    "\n",
    "        plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "dKmtue65TYwz0Yj68N9Tfm",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def sample_images(epoch, batch, gen_imgs, imgs):\n",
    "    plt.rcParams['figure.figsize'] = [15, 5]\n",
    "    fig, axs = plt.subplots(2, 5)\n",
    "    fig.suptitle('Epoch: ' + str(epoch) + ', Batch: ' + str(batch), fontsize=16)\n",
    "    for i in range(5):\n",
    "        \n",
    "        axs[0,i].imshow(gen_imgs[i][:,:,::-1])\n",
    "        axs[0,i].axis('off')\n",
    "\n",
    "    for i in range(5):\n",
    "        axs[1,i].imshow(imgs[i][:,:,::-1])\n",
    "        axs[1,i].axis('off')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "QYJZVLpiW9XymuJaNG70PX",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    plt.rcParams['figure.figsize'] = [20, 5]\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
    "\n",
    "    ax1.set_title('Losses')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.grid()\n",
    "\n",
    "    ax1.plot(history['d_loss'], label='D loss')\n",
    "    ax1.plot(history['g_loss'], label='G loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.set_title('D accuracy')\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax2.grid()\n",
    "\n",
    "    ax2.plot(history['d_acc'], label='Accuracy')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X_train, y_train, generator, discriminator, combined, epochs=100, batch_size=32, sample_interval=100)"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
